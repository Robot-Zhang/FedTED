""" transforms for process data before train/test when using torch"""
import collections
import pickle

import numpy as np
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
import torch
from .nlp_utils import *

MNIST_LIKE_DATASET = ['MNIST', 'FashionMNIST', 'EMNIST', 'femnist']
CIFAR_LIKE_DATASET = ['CIFAR10', 'CIFAR100']

F_to_tensor = transforms.ToTensor()  # H,W,C -> C,H,W

Glove6B300dPath = './datasets/processed_data/sent140-mini-embs.json'
RedditVocabPath = './datasets/raw/Leaf/reddit/reddit_vocab.pck'
REDDIT_MAX_SEQ = 25


def get_transform(dataset):
    """get transform and target transform for dataset"""
    if dataset in MNIST_LIKE_DATASET:
        return mnist_data_transform, int
    elif dataset in CIFAR_LIKE_DATASET:
        return cifar_data_transform, int
    elif dataset == 'celeba':
        return celeba_data_transform, int
    elif dataset == 'synthetic':
        return synthetic_data_transform, int
    elif dataset == 'sent140':
        sent_140 = Sent140_Trans(Glove6B300dPath)
        return sent_140.data_transform, int
    elif dataset == 'shakespeare':
        return shakespeare_data_transform, shakespeare_target_transform
    elif dataset == 'reddit':
        vocab_transform = RedditTrans(RedditVocabPath)
        return vocab_transform.transform, vocab_transform.reddit_target_transform
    else:
        raise NotImplementedError(f"transform for {dataset} not implemented.")


def mnist_data_transform(raw_x):
    raw_x = np.array(raw_x).reshape((28, 28, 1))
    max_norm = raw_x.max()
    x = F_to_tensor(raw_x).float() / max_norm
    return x


def cifar_data_transform(raw_x):
    raw_x = np.array(raw_x).reshape((32, 32, 3))
    max_norm = raw_x.max()
    x = F_to_tensor(raw_x).float() / max_norm
    return x


def celeba_data_transform(raw_x):
    raw_x = np.array(raw_x).reshape((84, 84, 3))
    max_norm = raw_x.max()
    x = F_to_tensor(raw_x).float() / max_norm
    return x


def synthetic_data_transform(raw_x):
    return torch.tensor(raw_x)


def sent140_pub_transform(raw_x, seq_len=1):
    return torch.tensor(raw_x).view(seq_len, -1)


def shakespeare_pub_transform(raw_x):
    x = np.array(raw_x) * 40
    x = np.clip(x, 0, 79, out=None)
    return torch.from_numpy(x).int()


"""transforms for NLP"""


class Sent140_Trans:

    def __init__(self, glove_6B_300d_path, bag_of_words=False, train_emb_layer=False, max_words=25):
        """ return transforms for sent 140

        Args:
            glove_6B_300d_path: path of `embs.json` generated by glove_6B_300d.
            bag_of_words: bool, if model is using bag_of_words.
            train_emb_layer: bool if rnn models' embedding layers trainable.
                If false, just return the embeddings according to glove_6B_300d.
            max_words: twitter's max words.
        """
        self.word_emb_arr, self.indd, self.vocab = get_word_emb_arr(glove_6B_300d_path)
        self.vocab_size = len(self.vocab)
        self.bag_of_words = bag_of_words
        self.train_emb_layer = train_emb_layer
        self.max_words = max_words

    def data_transform(self, raw_x):
        raw_x = raw_x[4]
        if self.bag_of_words:
            x = bag_of_words(raw_x, self.vocab)
            x = torch.Tensor(x)
        else:
            x = line_to_indices(raw_x, self.indd, self.max_words)
            if self.train_emb_layer:
                x = torch.Tensor(x).int()
            else:
                x = self.word_emb_arr[x]
                x = torch.from_numpy(x).float()
        return x


def shakespeare_data_transform(raw_x):
    x = word_to_indices(raw_x)
    x = torch.Tensor(x).int()
    return x


def shakespeare_target_transform(raw_y):
    return letter_index(raw_y)
